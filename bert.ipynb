{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6029383-a248-43d9-8030-7490f5d270c0",
   "metadata": {},
   "source": [
    "## CSV ÌååÏùº ÏùΩÍ∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beee34eb-e485-4aaa-b55a-041b7280d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the uploaded CSV files to check their structure and contents\n",
    "file_path_projections = \"C:/Users/PC/desktop/Î∞îÌÉï ÌôîÎ©¥/archive/indiana_projections.csv\"\n",
    "file_path_reports =\"C:/Users/PC/desktop/Î∞îÌÉï ÌôîÎ©¥/archive/indiana_reports.csv\"\n",
    "\n",
    "# Read the CSV files\n",
    "data_projections = pd.read_csv(file_path_projections)\n",
    "data_reports = pd.read_csv(file_path_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4aa935-d659-4eea-9c80-57e2ee8786ed",
   "metadata": {},
   "source": [
    "## Frontal\" ÌîÑÎ°úÏ†ùÏÖò Îç∞Ïù¥ÌÑ∞Îßå ÌïÑÌÑ∞ÎßÅ, Îç∞Ïù¥ÌÑ∞ÏôÄ Î≥ëÌï©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1a59e88-e737-452f-9035-756faf22b027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>filename</th>\n",
       "      <th>projection</th>\n",
       "      <th>MeSH</th>\n",
       "      <th>Problems</th>\n",
       "      <th>image</th>\n",
       "      <th>indication</th>\n",
       "      <th>comparison</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None.</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None.</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3_IM-1384-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>rib pain after a XXXX, XXXX XXXX steps this XX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No displaced rib fractures, pneumothorax, or p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4_IM-2050-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>PA and lateral views of the chest XXXX, XXXX a...</td>\n",
       "      <td>XXXX-year-old XXXX with XXXX.</td>\n",
       "      <td>None available</td>\n",
       "      <td>There are diffuse bilateral interstitial and a...</td>\n",
       "      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5_IM-2117-1003002.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>Osteophyte/thoracic vertebrae/multiple/small;T...</td>\n",
       "      <td>Osteophyte;Thickening;Lung</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Chest and nasal congestion.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The cardiomediastinal silhouette and pulmonary...</td>\n",
       "      <td>No acute cardiopulmonary abnormality.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                   filename projection  \\\n",
       "0    1     1_IM-0001-4001.dcm.png    Frontal   \n",
       "1    2     2_IM-0652-1001.dcm.png    Frontal   \n",
       "2    3     3_IM-1384-1001.dcm.png    Frontal   \n",
       "3    4     4_IM-2050-1001.dcm.png    Frontal   \n",
       "4    5  5_IM-2117-1003002.dcm.png    Frontal   \n",
       "\n",
       "                                                MeSH  \\\n",
       "0                                             normal   \n",
       "1  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "2                                             normal   \n",
       "3  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4  Osteophyte/thoracic vertebrae/multiple/small;T...   \n",
       "\n",
       "                                            Problems  \\\n",
       "0                                             normal   \n",
       "1                      Cardiomegaly;Pulmonary Artery   \n",
       "2                                             normal   \n",
       "3  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4                         Osteophyte;Thickening;Lung   \n",
       "\n",
       "                                               image  \\\n",
       "0                          Xray Chest PA and Lateral   \n",
       "1                Chest, 2 views, frontal and lateral   \n",
       "2                          Xray Chest PA and Lateral   \n",
       "3  PA and lateral views of the chest XXXX, XXXX a...   \n",
       "4                          Xray Chest PA and Lateral   \n",
       "\n",
       "                                          indication      comparison  \\\n",
       "0                                   Positive TB test           None.   \n",
       "1                           Preop bariatric surgery.           None.   \n",
       "2  rib pain after a XXXX, XXXX XXXX steps this XX...             NaN   \n",
       "3                      XXXX-year-old XXXX with XXXX.  None available   \n",
       "4                        Chest and nasal congestion.             NaN   \n",
       "\n",
       "                                            findings  \\\n",
       "0  The cardiac silhouette and mediastinum size ar...   \n",
       "1  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "2                                                NaN   \n",
       "3  There are diffuse bilateral interstitial and a...   \n",
       "4  The cardiomediastinal silhouette and pulmonary...   \n",
       "\n",
       "                                          impression  \n",
       "0                               Normal chest x-XXXX.  \n",
       "1                       No acute pulmonary findings.  \n",
       "2  No displaced rib fractures, pneumothorax, or p...  \n",
       "3  1. Bullous emphysema and interstitial fibrosis...  \n",
       "4              No acute cardiopulmonary abnormality.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for \"Frontal\" images in the projections dataset\n",
    "frontal_data = data_projections[data_projections['projection'] == 'Frontal']\n",
    "\n",
    "# Merge the frontal data with the reports data using 'uid' as the key\n",
    "merged_data = pd.merge(frontal_data, data_reports, on='uid', how='inner')\n",
    "\n",
    "# Check the resulting merged data\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623daca8-e1d8-4646-891b-1deb3f81db88",
   "metadata": {},
   "source": [
    "## BERT Î™®Îç∏ÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑÏôÄ Masked Language Modeling (MLM) Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§Î•º Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3263f283-e056-4897-b401-06e8a726278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the frontal data with the reports data using 'uid' as the key\n",
    "merged_data = pd.merge(frontal_data, data_reports, on='uid', how='inner')\n",
    "\n",
    "# Check the resulting merged data\n",
    "merged_data.head()\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# findingsÏôÄ impression Í≤∞Ìï©\n",
    "merged_data[\"report\"] = merged_data[\"findings\"].fillna(\"\") + \" \" + merged_data[\"impression\"].fillna(\"\")\n",
    "merged_data[\"report\"] = merged_data[\"report\"].str.strip()\n",
    "\n",
    "# ÌïÑÏöîÌïú Ïª¨Îüº ÏÑ†ÌÉù Î∞è NaN Ï†úÍ±∞\n",
    "merged_data = merged_data[[\"uid\", \"filename\", \"projection\", \"indication\", \"report\"]].dropna()\n",
    "\n",
    "# BERT Tokenizer Î°úÎìú\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# MLM Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "class MLM_Dataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        # BERT ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # ÎûúÎç§ ÎßàÏä§ÌÇπ Ï†ÅÏö© (MLM Î∞©Ïãù)\n",
    "        labels = input_ids.clone()\n",
    "        rand = torch.rand(input_ids.shape)\n",
    "        mask_arr = (rand < 0.15) * (input_ids != tokenizer.cls_token_id) * (input_ids != tokenizer.sep_token_id) * (input_ids != tokenizer.pad_token_id)\n",
    "        input_ids[mask_arr] = tokenizer.mask_token_id\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f38135-8abb-461d-9234-0af88e195a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è DataLoader ÏÉùÏÑ±\n",
    "mlm_dataset = MLM_Dataset(merged_data[\"report\"].tolist() + merged_data[\"indication\"].tolist(), tokenizer)\n",
    "mlm_dataloader = DataLoader(mlm_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Î™®Îç∏ Î°úÎìú\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73bb132c-81b7-40aa-a488-074b0be1404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üìù ÏõêÎ≥∏ ÌÖçÏä§Ìä∏:\n",
      " There is a 1 cm nodule within one of the lung bases, seen only on the lateral view. There is a calcified right hilar lymph node and right granuloma. Heart size is normal. No pneumothorax. 1 cm nodule within the lung base, seen only on the lateral view. Consider imaging correlation with XXXX abdomen study, if available. . \n",
      " ==================================================\n",
      "\n",
      "üîç ÎßàÏä§ÌÇπÎêú ÌÖçÏä§Ìä∏:\n",
      " There is a 1 cm nodule within one of the lung bases, seen only on the lateral view. There is a calcified right hilar lymph node and right granuloma. Heart size is normal. No pneumothorax. 1 cm nodule within the lung base, seen only on the lateral view. Consider imaging correlation with [MASK] abdomen study, if available. . \n",
      " ==================================================\n",
      "\n",
      "üéØ ÏòàÏ∏°Îêú ÌÖçÏä§Ìä∏:\n",
      " There is a 1 cm nodule within one of the lung bases, seen only on the lateral view. There is a calcified right hilar lymph node and right granuloma. Heart size is normal. No pneumothorax. 1 cm nodule within the lung base, seen only on the lateral view. Consider imaging correlation with the abdomen study, if available. . \n",
      " ==================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 'report' Ïª¨ÎüºÏóêÏÑú 'XXXX'Í∞Ä Ìè¨Ìï®Îêú Î¨∏Ïû•Îßå ÌïÑÌÑ∞ÎßÅ\n",
    "filtered_texts = [text for text in merged_data[\"report\"].dropna() if \"XXXX\" in text]\n",
    "\n",
    "# ÎûúÎç§ ÏÉòÌîå ÏÑ†ÌÉù (filtered_textsÍ∞Ä ÎπÑÏñ¥ ÏûàÏúºÎ©¥ Í∏∞Î≥∏Í∞í Ï†úÍ≥µ)\n",
    "sample_text = random.choice(filtered_texts) if filtered_texts else \"No valid text found.\"\n",
    "\n",
    "# ÎßàÏä§ÌÇπ ÏàòÌñâ\n",
    "masked_text = sample_text.replace(\"XXXX\", tokenizer.mask_token)\n",
    "\n",
    "# ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï Î∞è ÌÖêÏÑú Î≥ÄÌôò\n",
    "inputs = tokenizer(masked_text, return_tensors=\"pt\").to(device)\n",
    "mask_idx = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "\n",
    "# MLM ÏòàÏ∏° ÏàòÌñâ\n",
    "with torch.no_grad():\n",
    "    predictions = model(**inputs).logits\n",
    "\n",
    "# ÎßàÏä§ÌÅ¨Îêú ÌÜ†ÌÅ∞ ÏòàÏ∏° Î∞è Î≥µÏõê\n",
    "predicted_text = masked_text\n",
    "for idx in mask_idx.tolist():\n",
    "    predicted_token = tokenizer.decode(torch.argmax(predictions[0, idx]))\n",
    "    predicted_text = predicted_text.replace(tokenizer.mask_token, predicted_token, 1)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"=\" * 50)\n",
    "print(\"üìù ÏõêÎ≥∏ ÌÖçÏä§Ìä∏:\\n\", sample_text, \"\\n\", \"=\" * 50)\n",
    "print(\"\\nüîç ÎßàÏä§ÌÇπÎêú ÌÖçÏä§Ìä∏:\\n\", masked_text, \"\\n\", \"=\" * 50)\n",
    "print(\"\\nüéØ ÏòàÏ∏°Îêú ÌÖçÏä§Ìä∏:\\n\", predicted_text, \"\\n\", \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bb5a656-eb40-4ad1-b260-8c99b70372ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import BertForMaskedLM\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0231760c-a0f9-486b-8c88-7d1afdb4c844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataLoader for training\n",
    "# Set up the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define number of epochs\n",
    "epochs = 1\n",
    "\n",
    "# Training loop\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547809d5-23c5-45b5-99f5-1daa7987365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   5%|‚ñà‚ñà‚ñà‚ñå                                                              | 198/3733 [10:06<3:00:39,  3.07s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # tqdmÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Î∞∞Ïπò ÏßÑÌñâ ÏÉÅÌÉú ÌëúÏãú\n",
    "    for batch in tqdm(mlm_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\", leave=False):\n",
    "        # Move the batch to the device (GPU/CPU)\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss for reporting\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Average loss for this epoch\n",
    "    avg_loss = total_loss / len(mlm_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99c7f9-80d7-414a-b685-fbf316d6a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, you can evaluate the model on some validation or test set if you have one, \n",
    "# but since you only have the dataset, let's check the loss at the end.\n",
    "\n",
    "# Model evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform a test step with a single batch to check if everything works after training\n",
    "with torch.no_grad():\n",
    "    for batch in mlm_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        print(\"Test batch loss: \", outputs.loss.item())\n",
    "        break  # Stop after one batch for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac1e08-cb8d-4026-aabb-843ce9ecf321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9d146-3e98-43ec-964c-bde6a880734e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
