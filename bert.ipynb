{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6029383-a248-43d9-8030-7490f5d270c0",
   "metadata": {},
   "source": [
    "## CSV 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beee34eb-e485-4aaa-b55a-041b7280d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the uploaded CSV files to check their structure and contents\n",
    "file_path_projections = \"C:/Users/PC/desktop/바탕 화면/archive/indiana_projections.csv\"\n",
    "file_path_reports =\"C:/Users/PC/desktop/바탕 화면/archive/indiana_reports.csv\"\n",
    "\n",
    "# Read the CSV files\n",
    "data_projections = pd.read_csv(file_path_projections)\n",
    "data_reports = pd.read_csv(file_path_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4aa935-d659-4eea-9c80-57e2ee8786ed",
   "metadata": {},
   "source": [
    "## Frontal\" 프로젝션 데이터만 필터링, 데이터와 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1a59e88-e737-452f-9035-756faf22b027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>filename</th>\n",
       "      <th>projection</th>\n",
       "      <th>MeSH</th>\n",
       "      <th>Problems</th>\n",
       "      <th>image</th>\n",
       "      <th>indication</th>\n",
       "      <th>comparison</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None.</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None.</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3_IM-1384-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>rib pain after a XXXX, XXXX XXXX steps this XX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No displaced rib fractures, pneumothorax, or p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4_IM-2050-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>PA and lateral views of the chest XXXX, XXXX a...</td>\n",
       "      <td>XXXX-year-old XXXX with XXXX.</td>\n",
       "      <td>None available</td>\n",
       "      <td>There are diffuse bilateral interstitial and a...</td>\n",
       "      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5_IM-2117-1003002.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>Osteophyte/thoracic vertebrae/multiple/small;T...</td>\n",
       "      <td>Osteophyte;Thickening;Lung</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Chest and nasal congestion.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The cardiomediastinal silhouette and pulmonary...</td>\n",
       "      <td>No acute cardiopulmonary abnormality.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                   filename projection  \\\n",
       "0    1     1_IM-0001-4001.dcm.png    Frontal   \n",
       "1    2     2_IM-0652-1001.dcm.png    Frontal   \n",
       "2    3     3_IM-1384-1001.dcm.png    Frontal   \n",
       "3    4     4_IM-2050-1001.dcm.png    Frontal   \n",
       "4    5  5_IM-2117-1003002.dcm.png    Frontal   \n",
       "\n",
       "                                                MeSH  \\\n",
       "0                                             normal   \n",
       "1  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "2                                             normal   \n",
       "3  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4  Osteophyte/thoracic vertebrae/multiple/small;T...   \n",
       "\n",
       "                                            Problems  \\\n",
       "0                                             normal   \n",
       "1                      Cardiomegaly;Pulmonary Artery   \n",
       "2                                             normal   \n",
       "3  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4                         Osteophyte;Thickening;Lung   \n",
       "\n",
       "                                               image  \\\n",
       "0                          Xray Chest PA and Lateral   \n",
       "1                Chest, 2 views, frontal and lateral   \n",
       "2                          Xray Chest PA and Lateral   \n",
       "3  PA and lateral views of the chest XXXX, XXXX a...   \n",
       "4                          Xray Chest PA and Lateral   \n",
       "\n",
       "                                          indication      comparison  \\\n",
       "0                                   Positive TB test           None.   \n",
       "1                           Preop bariatric surgery.           None.   \n",
       "2  rib pain after a XXXX, XXXX XXXX steps this XX...             NaN   \n",
       "3                      XXXX-year-old XXXX with XXXX.  None available   \n",
       "4                        Chest and nasal congestion.             NaN   \n",
       "\n",
       "                                            findings  \\\n",
       "0  The cardiac silhouette and mediastinum size ar...   \n",
       "1  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "2                                                NaN   \n",
       "3  There are diffuse bilateral interstitial and a...   \n",
       "4  The cardiomediastinal silhouette and pulmonary...   \n",
       "\n",
       "                                          impression  \n",
       "0                               Normal chest x-XXXX.  \n",
       "1                       No acute pulmonary findings.  \n",
       "2  No displaced rib fractures, pneumothorax, or p...  \n",
       "3  1. Bullous emphysema and interstitial fibrosis...  \n",
       "4              No acute cardiopulmonary abnormality.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for \"Frontal\" images in the projections dataset\n",
    "frontal_data = data_projections[data_projections['projection'] == 'Frontal']\n",
    "\n",
    "# Merge the frontal data with the reports data using 'uid' as the key\n",
    "merged_data = pd.merge(frontal_data, data_reports, on='uid', how='inner')\n",
    "\n",
    "# Check the resulting merged data\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623daca8-e1d8-4646-891b-1deb3f81db88",
   "metadata": {},
   "source": [
    "## BERT 모델을 위한 데이터 준비와 Masked Language Modeling (MLM) 데이터셋 클래스를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3263f283-e056-4897-b401-06e8a726278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the frontal data with the reports data using 'uid' as the key\n",
    "merged_data = pd.merge(frontal_data, data_reports, on='uid', how='inner')\n",
    "\n",
    "# Check the resulting merged data\n",
    "merged_data.head()\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# findings와 impression 결합\n",
    "merged_data[\"report\"] = merged_data[\"findings\"].fillna(\"\") + \" \" + merged_data[\"impression\"].fillna(\"\")\n",
    "merged_data[\"report\"] = merged_data[\"report\"].str.strip()\n",
    "\n",
    "# 필요한 컬럼 선택 및 NaN 제거\n",
    "merged_data = merged_data[[\"uid\", \"filename\", \"projection\", \"indication\", \"report\"]].dropna()\n",
    "\n",
    "# BERT Tokenizer 로드\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# MLM 데이터셋 클래스 정의\n",
    "class MLM_Dataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        # BERT 토크나이징\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # 랜덤 마스킹 적용 (MLM 방식)\n",
    "        labels = input_ids.clone()\n",
    "        rand = torch.rand(input_ids.shape)\n",
    "        mask_arr = (rand < 0.15) * (input_ids != tokenizer.cls_token_id) * (input_ids != tokenizer.sep_token_id) * (input_ids != tokenizer.pad_token_id)\n",
    "        input_ids[mask_arr] = tokenizer.mask_token_id\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f38135-8abb-461d-9234-0af88e195a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# 데이터셋 및 DataLoader 생성\n",
    "mlm_dataset = MLM_Dataset(merged_data[\"report\"].tolist() + merged_data[\"indication\"].tolist(), tokenizer)\n",
    "mlm_dataloader = DataLoader(mlm_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73bb132c-81b7-40aa-a488-074b0be1404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "📝 원본 텍스트:\n",
      " There is a 1 cm nodule within one of the lung bases, seen only on the lateral view. There is a calcified right hilar lymph node and right granuloma. Heart size is normal. No pneumothorax. 1 cm nodule within the lung base, seen only on the lateral view. Consider imaging correlation with XXXX abdomen study, if available. . \n",
      " ==================================================\n",
      "\n",
      "🔍 마스킹된 텍스트:\n",
      " There is a 1 cm nodule within one of the lung bases, seen only on the lateral view. There is a calcified right hilar lymph node and right granuloma. Heart size is normal. No pneumothorax. 1 cm nodule within the lung base, seen only on the lateral view. Consider imaging correlation with [MASK] abdomen study, if available. . \n",
      " ==================================================\n",
      "\n",
      "🎯 예측된 텍스트:\n",
      " There is a 1 cm nodule within one of the lung bases, seen only on the lateral view. There is a calcified right hilar lymph node and right granuloma. Heart size is normal. No pneumothorax. 1 cm nodule within the lung base, seen only on the lateral view. Consider imaging correlation with the abdomen study, if available. . \n",
      " ==================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 'report' 컬럼에서 'XXXX'가 포함된 문장만 필터링\n",
    "filtered_texts = [text for text in merged_data[\"report\"].dropna() if \"XXXX\" in text]\n",
    "\n",
    "# 랜덤 샘플 선택 (filtered_texts가 비어 있으면 기본값 제공)\n",
    "sample_text = random.choice(filtered_texts) if filtered_texts else \"No valid text found.\"\n",
    "\n",
    "# 마스킹 수행\n",
    "masked_text = sample_text.replace(\"XXXX\", tokenizer.mask_token)\n",
    "\n",
    "# 토크나이징 및 텐서 변환\n",
    "inputs = tokenizer(masked_text, return_tensors=\"pt\").to(device)\n",
    "mask_idx = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "\n",
    "# MLM 예측 수행\n",
    "with torch.no_grad():\n",
    "    predictions = model(**inputs).logits\n",
    "\n",
    "# 마스크된 토큰 예측 및 복원\n",
    "predicted_text = masked_text\n",
    "for idx in mask_idx.tolist():\n",
    "    predicted_token = tokenizer.decode(torch.argmax(predictions[0, idx]))\n",
    "    predicted_text = predicted_text.replace(tokenizer.mask_token, predicted_token, 1)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=\" * 50)\n",
    "print(\"📝 원본 텍스트:\\n\", sample_text, \"\\n\", \"=\" * 50)\n",
    "print(\"\\n🔍 마스킹된 텍스트:\\n\", masked_text, \"\\n\", \"=\" * 50)\n",
    "print(\"\\n🎯 예측된 텍스트:\\n\", predicted_text, \"\\n\", \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bb5a656-eb40-4ad1-b260-8c99b70372ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import BertForMaskedLM\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0231760c-a0f9-486b-8c88-7d1afdb4c844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataLoader for training\n",
    "# Set up the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define number of epochs\n",
    "epochs = 1\n",
    "\n",
    "# Training loop\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547809d5-23c5-45b5-99f5-1daa7987365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   5%|███▌                                                              | 198/3733 [10:06<3:00:39,  3.07s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # tqdm을 사용하여 배치 진행 상태 표시\n",
    "    for batch in tqdm(mlm_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\", leave=False):\n",
    "        # Move the batch to the device (GPU/CPU)\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss for reporting\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Average loss for this epoch\n",
    "    avg_loss = total_loss / len(mlm_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99c7f9-80d7-414a-b685-fbf316d6a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, you can evaluate the model on some validation or test set if you have one, \n",
    "# but since you only have the dataset, let's check the loss at the end.\n",
    "\n",
    "# Model evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform a test step with a single batch to check if everything works after training\n",
    "with torch.no_grad():\n",
    "    for batch in mlm_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        print(\"Test batch loss: \", outputs.loss.item())\n",
    "        break  # Stop after one batch for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac1e08-cb8d-4026-aabb-843ce9ecf321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9d146-3e98-43ec-964c-bde6a880734e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
